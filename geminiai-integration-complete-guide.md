# Complete Google Gemini AI NestJS Integration Guide

## üìã T·ªïng quan v·ªÅ Google Gemini AI

Google Gemini AI l√† platform AI m·∫°nh m·∫Ω c·ªßa Google, cung c·∫•p c√°c capabilities nh∆∞:

- **Text Generation**: T·∫°o n·ªôi dung text th√¥ng minh
- **Multimodal Processing**: X·ª≠ l√Ω text + image ƒë·ªìng th·ªùi
- **Function Calling**: G·ªçi functions v·ªõi AI
- **Embeddings**: T·∫°o vector embeddings cho text
- **File Processing**: X·ª≠ l√Ω v√† ph√¢n t√≠ch files
- **Streaming**: Real-time content generation

---

## üöÄ Step 1: Setup Gemini API Dashboard & API Key

### 1.1 T·∫°o Project tr√™n Google AI Studio

1. **Truy c·∫≠p Google AI Studio**:

   ```
   https://aistudio.google.com/
   ```

2. **ƒêƒÉng nh·∫≠p v√† t·∫°o project**:
   - Click "Get API Key"
   - Ch·ªçn "Create API key in new project" ho·∫∑c ch·ªçn existing project
   - Copy API key ƒë∆∞·ª£c generate

3. **C·∫•u h√¨nh API Key**:
   ```env
   # .env file
   GEMINI_API_KEY=AIzaSyD-9tSrke4RbYiDQvO6Q-s9wFmS7J9xWw
   GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta
   ```

### 1.2 Test API Key

```bash
# Test v·ªõi curl
curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent" \
  -H "x-goog-api-key: YOUR_API_KEY" \
  -H 'Content-Type: application/json' \
  -X POST \
  -d '{
    "contents": [
      {
        "parts": [
          {
            "text": "Hello, how are you today?"
          }
        ]
      }
    ]
  }'
```

---

## üìÅ Step 2: Project Structure

```
libs/geminiai-client/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ client/generated/          # Auto-generated t·ª´ OpenAPI
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ oas.yml               # OpenAPI spec
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ providers.ts          # NestJS providers
‚îÇ   ‚îú‚îÄ‚îÄ geminiai-client.module.ts # NestJS dynamic module
‚îÇ   ‚îú‚îÄ‚îÄ geminiai-client.service.ts# Service wrapper
‚îÇ   ‚îî‚îÄ‚îÄ index.ts                  # Main exports
‚îî‚îÄ‚îÄ tsconfig.lib.json
```

---

## üîß Step 3: T·∫°o OpenAPI Specification

### `libs/geminiai-client/src/utils/oas.yml`

```yaml
openapi: 3.0.3
info:
  title: Google Gemini AI API
  version: 1.0.0
  description: |
    Google Gemini AI API for advanced generative AI capabilities.

    **Base URL**: https://generativelanguage.googleapis.com/v1beta

    **Authentication**: Include your API key in the `x-goog-api-key` header

    **Rate Limits**: 300 requests per minute across all endpoints

servers:
  - url: https://generativelanguage.googleapis.com/v1beta
    description: Production server

security:
  - ApiKeyAuth: []

paths:
  # MODELS
  /models:
    get:
      tags:
        - Models
      operationId: listModels
      summary: List Models
      description: Lists the models available through the API
      parameters:
        - name: pageSize
          in: query
          required: false
          schema:
            type: integer
            maximum: 1000
          description: The maximum number of Models to return
        - name: pageToken
          in: query
          required: false
          schema:
            type: string
          description: The page token from the previous response
      responses:
        '200':
          description: Models retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'

  /models/{modelId}:
    get:
      tags:
        - Models
      operationId: getModel
      summary: Get Model
      description: Gets information about a specific model
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
          description: The model ID (e.g., "gemini-2.5-flash")
      responses:
        '200':
          description: Model information retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelResponse'

  # CONTENT GENERATION
  /models/{modelId}:generateContent:
    post:
      tags:
        - Content Generation
      operationId: generateContent
      summary: Generate Content
      description: Generates content from the model given an input GenerateContentRequest
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
          description: The model ID (e.g., "gemini-2.5-flash")
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/GenerateContentRequest'
      responses:
        '200':
          description: Content generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GenerateContentResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '429':
          description: Rate limit exceeded

  /models/{modelId}:streamGenerateContent:
    post:
      tags:
        - Content Generation
      operationId: streamGenerateContent
      summary: Stream Generate Content
      description: Generates content from the model given an input and streams the response
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
          description: The model ID
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/GenerateContentRequest'
      responses:
        '200':
          description: Content stream started successfully
          content:
            text/plain:
              schema:
                type: string

  /models/{modelId}:countTokens:
    post:
      tags:
        - Content Generation
      operationId: countTokens
      summary: Count Tokens
      description: Runs a model's tokenizer on input content and returns the token count
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
          description: The model ID
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CountTokensRequest'
      responses:
        '200':
          description: Token count retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CountTokensResponse'

  # EMBEDDINGS
  /models/{modelId}:embedContent:
    post:
      tags:
        - Embeddings
      operationId: embedContent
      summary: Embed Content
      description: Generates an embedding from the model given an input
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
          description: The model ID (e.g., "text-embedding-004")
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbedContentRequest'
      responses:
        '200':
          description: Embedding generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbedContentResponse'

  /models/{modelId}:batchEmbedContents:
    post:
      tags:
        - Embeddings
      operationId: batchEmbedContents
      summary: Batch Embed Contents
      description: Generates embeddings for multiple contents in a batch
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
          description: The model ID
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/BatchEmbedContentsRequest'
      responses:
        '200':
          description: Batch embeddings generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchEmbedContentsResponse'

  # FILES
  /files:
    get:
      tags:
        - Files
      operationId: listFiles
      summary: List Files
      description: Lists the metadata for Files owned by the requesting project
      parameters:
        - name: pageSize
          in: query
          required: false
          schema:
            type: integer
            maximum: 100
          description: Maximum number of Files to return per page
        - name: pageToken
          in: query
          required: false
          schema:
            type: string
          description: The page token from the previous response
      responses:
        '200':
          description: Files retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'

    post:
      tags:
        - Files
      operationId: createFile
      summary: Create File
      description: Creates a File
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                metadata:
                  type: string
                  description: JSON metadata for the file
                file:
                  type: string
                  format: binary
                  description: The file to upload
      responses:
        '200':
          description: File created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileResponse'

  /files/{fileId}:
    get:
      tags:
        - Files
      operationId: getFile
      summary: Get File
      description: Gets the metadata for the given File
      parameters:
        - name: fileId
          in: path
          required: true
          schema:
            type: string
          description: The File ID
      responses:
        '200':
          description: File metadata retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileResponse'

    delete:
      tags:
        - Files
      operationId: deleteFile
      summary: Delete File
      description: Deletes the File
      parameters:
        - name: fileId
          in: path
          required: true
          schema:
            type: string
          description: The File ID
      responses:
        '200':
          description: File deleted successfully

components:
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: x-goog-api-key

  schemas:
    # CONTENT GENERATION SCHEMAS
    GenerateContentRequest:
      type: object
      required:
        - contents
      properties:
        contents:
          type: array
          items:
            $ref: '#/components/schemas/Content'
          description: The input given to the model as a prompt
        tools:
          type: array
          items:
            $ref: '#/components/schemas/Tool'
          description: A list of Tools available to the model
        safetySettings:
          type: array
          items:
            $ref: '#/components/schemas/SafetySetting'
          description: Safety settings to use for the request
        generationConfig:
          $ref: '#/components/schemas/GenerationConfig'
        systemInstruction:
          $ref: '#/components/schemas/Content'
          description: Developer set system instruction

    GenerateContentResponse:
      type: object
      properties:
        candidates:
          type: array
          items:
            $ref: '#/components/schemas/Candidate'
        promptFeedback:
          $ref: '#/components/schemas/PromptFeedback'
        usageMetadata:
          $ref: '#/components/schemas/UsageMetadata'

    Content:
      type: object
      required:
        - parts
      properties:
        parts:
          type: array
          items:
            $ref: '#/components/schemas/Part'
        role:
          type: string
          enum: [user, model]
          description: The producer of the content

    Part:
      type: object
      oneOf:
        - properties:
            text:
              type: string
              description: Text input
        - properties:
            inlineData:
              $ref: '#/components/schemas/Blob'
        - properties:
            functionCall:
              $ref: '#/components/schemas/FunctionCall'
        - properties:
            functionResponse:
              $ref: '#/components/schemas/FunctionResponse'
        - properties:
            fileData:
              $ref: '#/components/schemas/FileData'

    Blob:
      type: object
      required:
        - mimeType
        - data
      properties:
        mimeType:
          type: string
          description: The IANA standard MIME type
        data:
          type: string
          format: byte
          description: Raw bytes for media

    FileData:
      type: object
      required:
        - mimeType
        - fileUri
      properties:
        mimeType:
          type: string
          description: The IANA standard MIME type
        fileUri:
          type: string
          description: URI of the file

    Candidate:
      type: object
      properties:
        content:
          $ref: '#/components/schemas/Content'
        finishReason:
          type: string
          enum: [FINISH_REASON_UNSPECIFIED, STOP, MAX_TOKENS, SAFETY, RECITATION, OTHER]
        safetyRatings:
          type: array
          items:
            $ref: '#/components/schemas/SafetyRating'
        citationMetadata:
          $ref: '#/components/schemas/CitationMetadata'
        tokenCount:
          type: integer
        index:
          type: integer

    GenerationConfig:
      type: object
      properties:
        candidateCount:
          type: integer
          description: Number of generated responses to return
        stopSequences:
          type: array
          items:
            type: string
          description: Set of character sequences that will stop output generation
        maxOutputTokens:
          type: integer
          description: Maximum number of tokens to include in a candidate
        temperature:
          type: number
          minimum: 0.0
          maximum: 2.0
          description: Controls randomness of the output
        topP:
          type: number
          minimum: 0.0
          maximum: 1.0
          description: Maximum cumulative probability of tokens to consider
        topK:
          type: integer
          minimum: 1
          description: Maximum number of tokens to consider when sampling
        responseMimeType:
          type: string
          description: Output format of the generated candidate text
        responseSchema:
          type: object
          description: Output schema of the generated candidate text

    # FUNCTION CALLING SCHEMAS
    Tool:
      type: object
      properties:
        functionDeclarations:
          type: array
          items:
            $ref: '#/components/schemas/FunctionDeclaration'
        codeExecution:
          type: object
          description: Enable code execution tool

    FunctionDeclaration:
      type: object
      required:
        - name
      properties:
        name:
          type: string
          description: The name of the function
        description:
          type: string
          description: Description of the function
        parameters:
          type: object
          description: OpenAPI 3.0 schema object describing the function's parameters

    FunctionCall:
      type: object
      required:
        - name
      properties:
        name:
          type: string
        args:
          type: object

    FunctionResponse:
      type: object
      required:
        - name
        - response
      properties:
        name:
          type: string
        response:
          type: object

    # SAFETY SCHEMAS
    SafetySetting:
      type: object
      required:
        - category
        - threshold
      properties:
        category:
          type: string
          enum:
            [
              HARM_CATEGORY_UNSPECIFIED,
              HARM_CATEGORY_DEROGATORY,
              HARM_CATEGORY_TOXICITY,
              HARM_CATEGORY_VIOLENCE,
              HARM_CATEGORY_SEXUAL,
              HARM_CATEGORY_MEDICAL,
              HARM_CATEGORY_DANGEROUS,
            ]
        threshold:
          type: string
          enum:
            [HARM_BLOCK_THRESHOLD_UNSPECIFIED, BLOCK_LOW_AND_ABOVE, BLOCK_MEDIUM_AND_ABOVE, BLOCK_ONLY_HIGH, BLOCK_NONE]

    SafetyRating:
      type: object
      properties:
        category:
          type: string
          enum:
            [
              HARM_CATEGORY_UNSPECIFIED,
              HARM_CATEGORY_DEROGATORY,
              HARM_CATEGORY_TOXICITY,
              HARM_CATEGORY_VIOLENCE,
              HARM_CATEGORY_SEXUAL,
              HARM_CATEGORY_MEDICAL,
              HARM_CATEGORY_DANGEROUS,
            ]
        probability:
          type: string
          enum: [HARM_PROBABILITY_UNSPECIFIED, NEGLIGIBLE, LOW, MEDIUM, HIGH]

    PromptFeedback:
      type: object
      properties:
        blockReason:
          type: string
          enum: [BLOCK_REASON_UNSPECIFIED, SAFETY, OTHER]
        safetyRatings:
          type: array
          items:
            $ref: '#/components/schemas/SafetyRating'

    # EMBEDDINGS SCHEMAS
    EmbedContentRequest:
      type: object
      required:
        - content
      properties:
        content:
          $ref: '#/components/schemas/Content'
        taskType:
          type: string
          enum:
            [
              TASK_TYPE_UNSPECIFIED,
              RETRIEVAL_QUERY,
              RETRIEVAL_DOCUMENT,
              SEMANTIC_SIMILARITY,
              CLASSIFICATION,
              CLUSTERING,
            ]
        title:
          type: string
          description: An optional title for the content

    EmbedContentResponse:
      type: object
      properties:
        embedding:
          $ref: '#/components/schemas/ContentEmbedding'

    ContentEmbedding:
      type: object
      properties:
        values:
          type: array
          items:
            type: number
          description: The embedding values

    BatchEmbedContentsRequest:
      type: object
      required:
        - requests
      properties:
        requests:
          type: array
          items:
            $ref: '#/components/schemas/EmbedContentRequest'

    BatchEmbedContentsResponse:
      type: object
      properties:
        embeddings:
          type: array
          items:
            $ref: '#/components/schemas/ContentEmbedding'

    # TOKEN COUNTING SCHEMAS
    CountTokensRequest:
      type: object
      required:
        - contents
      properties:
        contents:
          type: array
          items:
            $ref: '#/components/schemas/Content'

    CountTokensResponse:
      type: object
      properties:
        totalTokens:
          type: integer
          description: The total number of tokens in the input

    # MODEL SCHEMAS
    ListModelsResponse:
      type: object
      properties:
        models:
          type: array
          items:
            $ref: '#/components/schemas/Model'
        nextPageToken:
          type: string

    ModelResponse:
      type: object
      properties:
        name:
          type: string
        baseModelId:
          type: string
        version:
          type: string
        displayName:
          type: string
        description:
          type: string
        inputTokenLimit:
          type: integer
        outputTokenLimit:
          type: integer
        supportedGenerationMethods:
          type: array
          items:
            type: string
        temperature:
          type: number
        maxTemperature:
          type: number
        topP:
          type: number
        topK:
          type: integer

    Model:
      type: object
      properties:
        name:
          type: string
          description: The resource name of the Model
        baseModelId:
          type: string
          description: Required for tuned models
        version:
          type: string
          description: The version number of the model
        displayName:
          type: string
          description: The human-readable name of the model
        description:
          type: string
          description: A short description of the model
        inputTokenLimit:
          type: integer
          description: Maximum number of input tokens allowed for this model
        outputTokenLimit:
          type: integer
          description: Maximum number of output tokens available for this model
        supportedGenerationMethods:
          type: array
          items:
            type: string
          description: The model's supported generation methods

    # FILE SCHEMAS
    FileResponse:
      type: object
      properties:
        name:
          type: string
          description: The resource name of the File
        displayName:
          type: string
          description: The human-readable display name for the File
        mimeType:
          type: string
          description: MIME type of the file
        sizeBytes:
          type: string
          format: int64
          description: Size of the file in bytes
        createTime:
          type: string
          format: date-time
          description: The timestamp of when the File was created
        updateTime:
          type: string
          format: date-time
          description: The timestamp of when the File was last updated
        expirationTime:
          type: string
          format: date-time
          description: The timestamp of when the File will be deleted
        sha256Hash:
          type: string
          format: byte
          description: SHA-256 hash of the uploaded bytes
        uri:
          type: string
          description: The uri of the File
        state:
          type: string
          enum: [STATE_UNSPECIFIED, PROCESSING, ACTIVE, FAILED]
        error:
          $ref: '#/components/schemas/Status'

    ListFilesResponse:
      type: object
      properties:
        files:
          type: array
          items:
            $ref: '#/components/schemas/FileResponse'
        nextPageToken:
          type: string

    # METADATA SCHEMAS
    UsageMetadata:
      type: object
      properties:
        promptTokenCount:
          type: integer
        candidatesTokenCount:
          type: integer
        totalTokenCount:
          type: integer

    CitationMetadata:
      type: object
      properties:
        citationSources:
          type: array
          items:
            $ref: '#/components/schemas/CitationSource'

    CitationSource:
      type: object
      properties:
        startIndex:
          type: integer
        endIndex:
          type: integer
        uri:
          type: string
        license:
          type: string

    # ERROR SCHEMAS
    Status:
      type: object
      properties:
        code:
          type: integer
        message:
          type: string
        details:
          type: array
          items:
            type: object

    ErrorResponse:
      type: object
      properties:
        error:
          $ref: '#/components/schemas/Status'
```

---

## üîß Step 4: Update openapitools.json

Th√™m Gemini AI client v√†o root `openapitools.json`:

```json
{
  "$schema": "./node_modules/@openapitools/openapi-generator-cli/config.schema.json",
  "spaces": 2,
  "generator-cli": {
    "version": "7.6.0",
    "generators": {
      "geminiai-client": {
        "generatorName": "typescript-axios",
        "inputSpec": "libs/geminiai-client/src/utils/oas.yml",
        "output": "libs/geminiai-client/src/client/generated",
        "additionalProperties": {
          "stringEnums": true,
          "supportsES6": true,
          "typescriptThreePlus": true,
          "enumPropertyNaming": "original",
          "useSingleRequestParameter": true,
          "withNodeImports": true
        }
      }
    }
  }
}
```

---

## üì¶ Step 5: T·∫°o NestJS Providers

### `libs/geminiai-client/src/utils/providers.ts`

```typescript
import { HttpService } from '@nestjs/axios'
import { FactoryProvider } from '@nestjs/common'
import { AxiosInstance } from 'axios'
import { Configuration } from '../client/generated'

export function injectGeminiApiProvider<T>(
  ApiClass: new ({
    configuration,
    basePath,
    axios,
  }: {
    configuration?: Configuration
    basePath?: string
    axios?: AxiosInstance
  }) => T,
): FactoryProvider<T> {
  return {
    provide: ApiClass,
    inject: [HttpService],
    useFactory: (httpService: HttpService) => {
      const config = new Configuration({
        basePath: process.env.GEMINI_BASE_URL || 'https://generativelanguage.googleapis.com/v1beta',
        apiKey: process.env.GEMINI_API_KEY,
      })

      // Add request interceptor for API key
      httpService.axiosRef.interceptors.request.use((config) => {
        if (process.env.GEMINI_API_KEY) {
          config.headers['x-goog-api-key'] = process.env.GEMINI_API_KEY
        }
        return config
      })

      // Add response interceptor for error handling
      httpService.axiosRef.interceptors.response.use(
        (response) => response,
        (error) => {
          if (error.response) {
            // Rate limit handling
            if (error.response.status === 429) {
              console.warn('Gemini API rate limit exceeded. Please wait before making another request.')
            }
            // Quota exceeded handling
            if (error.response.status === 403) {
              console.warn('Gemini API quota exceeded or invalid API key.')
            }
          }
          return Promise.reject(error)
        },
      )

      return new ApiClass({
        configuration: config,
        basePath: config.basePath,
        axios: httpService.axiosRef,
      })
    },
  }
}

// Token symbols for dependency injection
export const GEMINI_CONTENT_GENERATION_API = Symbol('GEMINI_CONTENT_GENERATION_API')
export const GEMINI_MODELS_API = Symbol('GEMINI_MODELS_API')
export const GEMINI_EMBEDDINGS_API = Symbol('GEMINI_EMBEDDINGS_API')
export const GEMINI_FILES_API = Symbol('GEMINI_FILES_API')
```

---

## üì¶ Step 6: T·∫°o NestJS Dynamic Module

### `libs/geminiai-client/src/geminiai-client.module.ts`

```typescript
import { DynamicModule, Global, Module, Provider } from '@nestjs/common'
import { HttpModule } from '@nestjs/axios'
import { ConfigModule } from '@nestjs/config'
import { ContentGenerationApi, ModelsApi, EmbeddingsApi, FilesApi } from './client/generated'
import { injectGeminiApiProvider } from './utils/providers'
import { GeminiAIClientService } from './geminiai-client.service'

export interface GeminiAIModuleOptions {
  apiKey: string
  baseUrl?: string
  timeout?: number
}

export interface GeminiAIModuleAsyncOptions {
  imports?: any[]
  useFactory: (...args: any[]) => Promise<GeminiAIModuleOptions> | GeminiAIModuleOptions
  inject?: any[]
}

@Global()
@Module({})
export class GeminiAIClientModule {
  static forRoot(options: GeminiAIModuleOptions): DynamicModule {
    const providers: Provider[] = [
      {
        provide: 'GEMINI_OPTIONS',
        useValue: options,
      },
      injectGeminiApiProvider(ContentGenerationApi),
      injectGeminiApiProvider(ModelsApi),
      injectGeminiApiProvider(EmbeddingsApi),
      injectGeminiApiProvider(FilesApi),
      GeminiAIClientService,
    ]

    return {
      module: GeminiAIClientModule,
      imports: [HttpModule, ConfigModule],
      providers,
      exports: [ContentGenerationApi, ModelsApi, EmbeddingsApi, FilesApi, GeminiAIClientService],
    }
  }

  static forRootAsync(options: GeminiAIModuleAsyncOptions): DynamicModule {
    const asyncProviders: Provider[] = [
      {
        provide: 'GEMINI_OPTIONS',
        useFactory: options.useFactory,
        inject: options.inject || [],
      },
      injectGeminiApiProvider(ContentGenerationApi),
      injectGeminiApiProvider(ModelsApi),
      injectGeminiApiProvider(EmbeddingsApi),
      injectGeminiApiProvider(FilesApi),
      GeminiAIClientService,
    ]

    return {
      module: GeminiAIClientModule,
      imports: [HttpModule, ConfigModule, ...(options.imports || [])],
      providers: asyncProviders,
      exports: [ContentGenerationApi, ModelsApi, EmbeddingsApi, FilesApi, GeminiAIClientService],
    }
  }
}
```

---

## üéØ Step 7: T·∫°o Service Wrapper

### `libs/geminiai-client/src/geminiai-client.service.ts`

```typescript
import {
  BadRequestException,
  Injectable,
  NotFoundException,
  UnauthorizedException,
  Logger,
  InternalServerErrorException,
  Inject,
} from '@nestjs/common'
import {
  ContentGenerationApi,
  ModelsApi,
  EmbeddingsApi,
  FilesApi,
  GenerateContentRequest,
  EmbedContentRequest,
  CountTokensRequest,
  BatchEmbedContentsRequest,
  Content,
  GenerationConfig,
  SafetySetting,
  Tool,
} from './client/generated'
import { AxiosError } from 'axios'
import { Observable } from 'rxjs'

@Injectable()
export class GeminiAIClientService {
  private readonly logger = new Logger(GeminiAIClientService.name)

  constructor(
    @Inject('GEMINI_OPTIONS') private readonly options: any,
    private readonly contentGenerationApi: ContentGenerationApi,
    private readonly modelsApi: ModelsApi,
    private readonly embeddingsApi: EmbeddingsApi,
    private readonly filesApi: FilesApi,
  ) {}

  private handleError(error: any, operation: string) {
    this.logger.error(`${operation} failed:`, error)

    if (error.response) {
      const status = error.response.status
      const message = error.response.data?.error?.message || error.message

      switch (status) {
        case 400:
          throw new BadRequestException(`Invalid request: ${message}`)
        case 401:
          throw new UnauthorizedException('Invalid Gemini API key or unauthorized access')
        case 403:
          throw new BadRequestException('Quota exceeded or permission denied')
        case 404:
          throw new NotFoundException(message || 'Resource not found')
        case 429:
          throw new BadRequestException('Rate limit exceeded. Please try again later.')
        case 500:
          throw new InternalServerErrorException('Internal server error from Gemini API')
        default:
          throw new InternalServerErrorException(`Gemini API error: ${message}`)
      }
    }

    throw new InternalServerErrorException(`${operation} failed: ${error.message}`)
  }

  // ==================== CONTENT GENERATION ====================

  /**
   * Generate content using Gemini AI
   */
  async generateContent(modelId: string = 'gemini-2.5-flash', request: GenerateContentRequest) {
    try {
      const response = await this.contentGenerationApi.generateContent(modelId, request)

      this.logger.log(`Content generated successfully for model: ${modelId}`)
      return response.data
    } catch (error) {
      this.handleError(error, 'Generate Content')
    }
  }

  /**
   * Generate content with simple text input
   */
  async generateText(
    text: string,
    modelId: string = 'gemini-2.5-flash',
    options?: {
      generationConfig?: GenerationConfig
      safetySettings?: SafetySetting[]
      systemInstruction?: string
    },
  ) {
    try {
      const request: GenerateContentRequest = {
        contents: [
          {
            parts: [{ text }],
          },
        ],
        generationConfig: options?.generationConfig,
        safetySettings: options?.safetySettings,
        systemInstruction: options?.systemInstruction ? { parts: [{ text: options.systemInstruction }] } : undefined,
      }

      return await this.generateContent(modelId, request)
    } catch (error) {
      this.handleError(error, 'Generate Text')
    }
  }

  /**
   * Generate content with multimodal input (text + image)
   */
  async generateMultimodalContent(
    text: string,
    imageData: {
      mimeType: string
      data: string // base64 encoded
    },
    modelId: string = 'gemini-2.5-flash',
    options?: {
      generationConfig?: GenerationConfig
      safetySettings?: SafetySetting[]
    },
  ) {
    try {
      const request: GenerateContentRequest = {
        contents: [
          {
            parts: [{ text }, { inlineData: imageData }],
          },
        ],
        generationConfig: options?.generationConfig,
        safetySettings: options?.safetySettings,
      }

      return await this.generateContent(modelId, request)
    } catch (error) {
      this.handleError(error, 'Generate Multimodal Content')
    }
  }

  /**
   * Generate content with function calling
   */
  async generateContentWithFunctions(
    text: string,
    tools: Tool[],
    modelId: string = 'gemini-2.5-flash',
    options?: {
      generationConfig?: GenerationConfig
      safetySettings?: SafetySetting[]
    },
  ) {
    try {
      const request: GenerateContentRequest = {
        contents: [
          {
            parts: [{ text }],
          },
        ],
        tools,
        generationConfig: options?.generationConfig,
        safetySettings: options?.safetySettings,
      }

      return await this.generateContent(modelId, request)
    } catch (error) {
      this.handleError(error, 'Generate Content With Functions')
    }
  }

  /**
   * Stream generate content
   */
  async streamGenerateContent(
    modelId: string = 'gemini-2.5-flash',
    request: GenerateContentRequest,
  ): Promise<Observable<any>> {
    try {
      const response = await this.contentGenerationApi.streamGenerateContent(modelId, request)

      this.logger.log(`Content streaming started for model: ${modelId}`)
      return response.data as any
    } catch (error) {
      this.handleError(error, 'Stream Generate Content')
    }
  }

  /**
   * Count tokens in content
   */
  async countTokens(modelId: string = 'gemini-2.5-flash', contents: Content[]) {
    try {
      const request: CountTokensRequest = { contents }

      const response = await this.contentGenerationApi.countTokens(modelId, request)

      return response.data
    } catch (error) {
      this.handleError(error, 'Count Tokens')
    }
  }

  // ==================== MODELS ====================

  /**
   * List available models
   */
  async listModels(pageSize?: number, pageToken?: string) {
    try {
      const response = await this.modelsApi.listModels(pageSize, pageToken)
      return response.data
    } catch (error) {
      this.handleError(error, 'List Models')
    }
  }

  /**
   * Get specific model information
   */
  async getModel(modelId: string) {
    try {
      const response = await this.modelsApi.getModel(modelId)
      return response.data
    } catch (error) {
      this.handleError(error, 'Get Model')
    }
  }

  // ==================== EMBEDDINGS ====================

  /**
   * Generate embedding for content
   */
  async embedContent(
    content: Content,
    modelId: string = 'text-embedding-004',
    options?: {
      taskType?: string
      title?: string
    },
  ) {
    try {
      const request: EmbedContentRequest = {
        content,
        taskType: options?.taskType,
        title: options?.title,
      }

      const response = await this.embeddingsApi.embedContent(modelId, request)
      return response.data
    } catch (error) {
      this.handleError(error, 'Embed Content')
    }
  }

  /**
   * Generate embedding for text
   */
  async embedText(
    text: string,
    modelId: string = 'text-embedding-004',
    options?: {
      taskType?: string
      title?: string
    },
  ) {
    try {
      const content: Content = {
        parts: [{ text }],
      }

      return await this.embedContent(content, modelId, options)
    } catch (error) {
      this.handleError(error, 'Embed Text')
    }
  }

  /**
   * Batch generate embeddings
   */
  async batchEmbedContents(requests: EmbedContentRequest[], modelId: string = 'text-embedding-004') {
    try {
      const batchRequest: BatchEmbedContentsRequest = { requests }

      const response = await this.embeddingsApi.batchEmbedContents(modelId, batchRequest)

      this.logger.log(`Batch embeddings generated for ${requests.length} items`)
      return response.data
    } catch (error) {
      this.handleError(error, 'Batch Embed Contents')
    }
  }

  // ==================== FILES ====================

  /**
   * List files
   */
  async listFiles(pageSize?: number, pageToken?: string) {
    try {
      const response = await this.filesApi.listFiles(pageSize, pageToken)
      return response.data
    } catch (error) {
      this.handleError(error, 'List Files')
    }
  }

  /**
   * Get file information
   */
  async getFile(fileId: string) {
    try {
      const response = await this.filesApi.getFile(fileId)
      return response.data
    } catch (error) {
      this.handleError(error, 'Get File')
    }
  }

  /**
   * Delete file
   */
  async deleteFile(fileId: string) {
    try {
      await this.filesApi.deleteFile(fileId)
      this.logger.log(`File deleted successfully: ${fileId}`)
    } catch (error) {
      this.handleError(error, 'Delete File')
    }
  }

  // ==================== UTILITY METHODS ====================

  /**
   * Create a complete chat conversation
   */
  async createChatConversation(
    messages: Array<{
      role: 'user' | 'model'
      content: string
    }>,
    modelId: string = 'gemini-2.5-flash',
    options?: {
      generationConfig?: GenerationConfig
      safetySettings?: SafetySetting[]
      systemInstruction?: string
    },
  ) {
    try {
      const contents: Content[] = messages.map((message) => ({
        role: message.role,
        parts: [{ text: message.content }],
      }))

      const request: GenerateContentRequest = {
        contents,
        generationConfig: options?.generationConfig,
        safetySettings: options?.safetySettings,
        systemInstruction: options?.systemInstruction ? { parts: [{ text: options.systemInstruction }] } : undefined,
      }

      return await this.generateContent(modelId, request)
    } catch (error) {
      this.handleError(error, 'Create Chat Conversation')
    }
  }

  /**
   * Generate content with retry logic
   */
  async generateContentWithRetry(
    modelId: string = 'gemini-2.5-flash',
    request: GenerateContentRequest,
    maxRetries: number = 3,
    retryDelay: number = 1000,
  ) {
    let lastError: any

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        return await this.generateContent(modelId, request)
      } catch (error) {
        lastError = error

        // Don't retry on certain error types
        if (error instanceof BadRequestException || error instanceof UnauthorizedException) {
          throw error
        }

        if (attempt < maxRetries) {
          this.logger.warn(`Attempt ${attempt} failed, retrying in ${retryDelay}ms...`)
          await new Promise((resolve) => setTimeout(resolve, retryDelay))
          retryDelay *= 2 // Exponential backoff
        }
      }
    }

    throw lastError
  }

  /**
   * Analyze image with specific prompts
   */
  async analyzeImage(
    imageBase64: string,
    mimeType: string,
    prompt: string = 'Describe this image in detail',
    modelId: string = 'gemini-2.5-flash',
  ) {
    try {
      return await this.generateMultimodalContent(
        prompt,
        {
          mimeType,
          data: imageBase64,
        },
        modelId,
      )
    } catch (error) {
      this.handleError(error, 'Analyze Image')
    }
  }

  /**
   * Generate structured JSON response
   */
  async generateStructuredResponse(text: string, schema: object, modelId: string = 'gemini-2.5-flash') {
    try {
      const generationConfig: GenerationConfig = {
        responseMimeType: 'application/json',
        responseSchema: schema,
      }

      return await this.generateText(text, modelId, { generationConfig })
    } catch (error) {
      this.handleError(error, 'Generate Structured Response')
    }
  }
}
```

---

## üìÅ Step 8: T·∫°o Index Export

### `libs/geminiai-client/src/index.ts`

```typescript
// Re-export everything from generated client
export * from './client/generated'

// Export module and service
export * from './geminiai-client.module'
export * from './geminiai-client.service'
export * from './utils/providers'

// Export types and interfaces
export interface GeminiAIModuleOptions {
  apiKey: string
  baseUrl?: string
  timeout?: number
}

export interface GeminiAIModuleAsyncOptions {
  imports?: any[]
  useFactory: (...args: any[]) => Promise<GeminiAIModuleOptions> | GeminiAIModuleOptions
  inject?: any[]
}
```

---

## ‚öôÔ∏è Step 9: Update tsconfig v√† package.json

### Update `tsconfig.json` (Root)

```json
{
  "compilerOptions": {
    "paths": {
      "@nnpp/geminiai-client": ["libs/geminiai-client/src/index.ts"],
      "@nnpp/geminiai-client/*": ["libs/geminiai-client/src/*"]
    }
  }
}
```

### Update `package.json` - Jest config

```json
{
  "jest": {
    "moduleNameMapper": {
      "^@nnpp/geminiai-client(|/.*)$": "<rootDir>/libs/geminiai-client/src/$1"
    }
  }
}
```

---

## üîß Step 10: Environment Configuration

### `.env` file

```env
# Gemini AI Configuration
GEMINI_API_KEY=AIzaSyD-9tSrke4RbYiDQvO6Q-s9wFmS7J9xWw
GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta
```

---

## üöÄ Step 11: Generate Client Code

```bash
# Generate Gemini AI client
pnpm codegen

# Or generate specific client
npx openapi-generator-cli generate -g geminiai-client

# Fix linting issues
pnpm post-codegen
```

---

## üíª Step 12: S·ª≠ d·ª•ng trong Application

### `apps/bff-service/src/app.module.ts`

```typescript
import { Module } from '@nestjs/common'
import { ConfigModule } from '@nestjs/config'
import { GeminiAIClientModule } from '@nnpp/geminiai-client'
import { AIController } from './controllers/ai.controller'
import { AIService } from './services/ai.service'

@Module({
  imports: [
    ConfigModule.forRoot(),
    GeminiAIClientModule.forRootAsync({
      imports: [ConfigModule],
      useFactory: async (configService: ConfigService) => ({
        apiKey: configService.get('GEMINI_API_KEY'),
        baseUrl: configService.get('GEMINI_BASE_URL'),
        timeout: 30000,
      }),
      inject: [ConfigService],
    }),
  ],
  controllers: [AIController],
  providers: [AIService],
})
export class AppModule {}
```

### `apps/bff-service/src/services/ai.service.ts`

```typescript
import { Injectable, Logger } from '@nestjs/common'
import {
  GeminiAIClientService,
  GenerationConfig,
  SafetySetting,
  Tool,
  FunctionDeclaration,
} from '@nnpp/geminiai-client'

@Injectable()
export class AIService {
  private readonly logger = new Logger(AIService.name)

  constructor(private readonly geminiService: GeminiAIClientService) {}

  /**
   * Generate simple text response
   */
  async generateText(prompt: string) {
    try {
      const config: GenerationConfig = {
        temperature: 0.7,
        maxOutputTokens: 2048,
        topP: 0.8,
        topK: 40,
      }

      const response = await this.geminiService.generateText(prompt, 'gemini-2.5-flash', { generationConfig: config })

      return {
        text: response.candidates?.[0]?.content?.parts?.[0]?.text,
        usage: response.usageMetadata,
        finishReason: response.candidates?.[0]?.finishReason,
      }
    } catch (error) {
      this.logger.error('Failed to generate text:', error)
      throw error
    }
  }

  /**
   * Analyze image with AI
   */
  async analyzeImage(imageBase64: string, mimeType: string, prompt?: string) {
    try {
      const analysisPrompt = prompt || 'Analyze this image and describe what you see in detail.'

      const response = await this.geminiService.analyzeImage(imageBase64, mimeType, analysisPrompt)

      return {
        analysis: response.candidates?.[0]?.content?.parts?.[0]?.text,
        usage: response.usageMetadata,
      }
    } catch (error) {
      this.logger.error('Failed to analyze image:', error)
      throw error
    }
  }

  /**
   * Generate structured JSON response
   */
  async generateStructuredData(prompt: string, schema: object) {
    try {
      const response = await this.geminiService.generateStructuredResponse(prompt, schema)

      return {
        data: JSON.parse(response.candidates?.[0]?.content?.parts?.[0]?.text || '{}'),
        usage: response.usageMetadata,
      }
    } catch (error) {
      this.logger.error('Failed to generate structured data:', error)
      throw error
    }
  }

  /**
   * Chat conversation with context
   */
  async chatConversation(
    messages: Array<{
      role: 'user' | 'model'
      content: string
    }>,
    systemInstruction?: string,
  ) {
    try {
      const config: GenerationConfig = {
        temperature: 0.9,
        maxOutputTokens: 8192,
        topP: 1,
      }

      const safetySettings: SafetySetting[] = [
        {
          category: 'HARM_CATEGORY_TOXICITY',
          threshold: 'BLOCK_MEDIUM_AND_ABOVE',
        },
        {
          category: 'HARM_CATEGORY_VIOLENCE',
          threshold: 'BLOCK_MEDIUM_AND_ABOVE',
        },
      ]

      const response = await this.geminiService.createChatConversation(messages, 'gemini-2.5-flash', {
        generationConfig: config,
        safetySettings,
        systemInstruction,
      })

      return {
        reply: response.candidates?.[0]?.content?.parts?.[0]?.text,
        usage: response.usageMetadata,
        safetyRatings: response.candidates?.[0]?.safetyRatings,
      }
    } catch (error) {
      this.logger.error('Failed to process chat conversation:', error)
      throw error
    }
  }

  /**
   * Function calling example
   */
  async callFunctions(prompt: string) {
    try {
      // Define available functions
      const weatherFunction: FunctionDeclaration = {
        name: 'get_weather',
        description: 'Get weather information for a location',
        parameters: {
          type: 'object',
          properties: {
            location: {
              type: 'string',
              description: 'The location to get weather for',
            },
            unit: {
              type: 'string',
              enum: ['celsius', 'fahrenheit'],
              description: 'Temperature unit',
            },
          },
          required: ['location'],
        },
      }

      const calculatorFunction: FunctionDeclaration = {
        name: 'calculate',
        description: 'Perform mathematical calculations',
        parameters: {
          type: 'object',
          properties: {
            expression: {
              type: 'string',
              description: 'Mathematical expression to evaluate',
            },
          },
          required: ['expression'],
        },
      }

      const tools: Tool[] = [
        {
          functionDeclarations: [weatherFunction, calculatorFunction],
        },
      ]

      const response = await this.geminiService.generateContentWithFunctions(prompt, tools)

      return {
        response: response.candidates?.[0]?.content?.parts,
        usage: response.usageMetadata,
      }
    } catch (error) {
      this.logger.error('Failed to call functions:', error)
      throw error
    }
  }

  /**
   * Generate embeddings for semantic search
   */
  async generateEmbeddings(texts: string[]) {
    try {
      const requests = texts.map((text) => ({
        content: { parts: [{ text }] },
        taskType: 'SEMANTIC_SIMILARITY',
      }))

      const response = await this.geminiService.batchEmbedContents(requests)

      return {
        embeddings: response.embeddings?.map((e) => e.values) || [],
        count: response.embeddings?.length || 0,
      }
    } catch (error) {
      this.logger.error('Failed to generate embeddings:', error)
      throw error
    }
  }

  /**
   * Count tokens for content
   */
  async countTokens(content: string) {
    try {
      const response = await this.geminiService.countTokens('gemini-2.5-flash', [{ parts: [{ text: content }] }])

      return {
        totalTokens: response.totalTokens,
      }
    } catch (error) {
      this.logger.error('Failed to count tokens:', error)
      throw error
    }
  }

  /**
   * List available models
   */
  async getAvailableModels() {
    try {
      const response = await this.geminiService.listModels()

      return {
        models:
          response.models?.map((model) => ({
            name: model.name,
            displayName: model.displayName,
            description: model.description,
            inputTokenLimit: model.inputTokenLimit,
            outputTokenLimit: model.outputTokenLimit,
          })) || [],
      }
    } catch (error) {
      this.logger.error('Failed to get available models:', error)
      throw error
    }
  }
}
```

### `apps/bff-service/src/controllers/ai.controller.ts`

```typescript
import { Body, Controller, Get, Logger, Post, Query, UploadedFile, UseInterceptors } from '@nestjs/common'
import { FileInterceptor } from '@nestjs/platform-express'
import { AIService } from '../services/ai.service'

@Controller('ai')
export class AIController {
  private readonly logger = new Logger(AIController.name)

  constructor(private readonly aiService: AIService) {}

  @Post('generate-text')
  async generateText(@Body() body: { prompt: string }) {
    try {
      const result = await this.aiService.generateText(body.prompt)
      return {
        success: true,
        data: result,
      }
    } catch (error) {
      this.logger.error('Generate text failed:', error)
      throw error
    }
  }

  @Post('analyze-image')
  @UseInterceptors(FileInterceptor('image'))
  async analyzeImage(@UploadedFile() file: Express.Multer.File, @Body() body: { prompt?: string }) {
    try {
      if (!file) {
        throw new Error('No image file provided')
      }

      const imageBase64 = file.buffer.toString('base64')
      const result = await this.aiService.analyzeImage(imageBase64, file.mimetype, body.prompt)

      return {
        success: true,
        data: result,
      }
    } catch (error) {
      this.logger.error('Analyze image failed:', error)
      throw error
    }
  }

  @Post('chat')
  async chat(
    @Body() body: { messages: Array<{ role: 'user' | 'model'; content: string }>; systemInstruction?: string },
  ) {
    try {
      const result = await this.aiService.chatConversation(body.messages, body.systemInstruction)

      return {
        success: true,
        data: result,
      }
    } catch (error) {
      this.logger.error('Chat failed:', error)
      throw error
    }
  }

  @Post('structured-data')
  async generateStructuredData(@Body() body: { prompt: string; schema: object }) {
    try {
      const result = await this.aiService.generateStructuredData(body.prompt, body.schema)

      return {
        success: true,
        data: result,
      }
    } catch (error) {
      this.logger.error('Generate structured data failed:', error)
      throw error
    }
  }

  @Post('embeddings')
  async generateEmbeddings(@Body() body: { texts: string[] }) {
    try {
      const result = await this.aiService.generateEmbeddings(body.texts)
      return {
        success: true,
        data: result,
      }
    } catch (error) {
      this.logger.error('Generate embeddings failed:', error)
      throw error
    }
  }

  @Post('functions')
  async callFunctions(@Body() body: { prompt: string }) {
    try {
      const result = await this.aiService.callFunctions(body.prompt)
      return {
        success: true,
        data: result,
      }
    } catch (error) {
      this.logger.error('Function calling failed:', error)
      throw error
    }
  }

  @Get('models')
  async getModels() {
    try {
      const result = await this.aiService.getAvailableModels()
      return {
        success: true,
        data: result,
      }
    } catch (error) {
      this.logger.error('Get models failed:', error)
      throw error
    }
  }

  @Post('count-tokens')
  async countTokens(@Body() body: { content: string }) {
    try {
      const result = await this.aiService.countTokens(body.content)
      return {
        success: true,
        data: result,
      }
    } catch (error) {
      this.logger.error('Count tokens failed:', error)
      throw error
    }
  }
}
```

---

## üß™ Step 13: Testing

### Create test file `libs/geminiai-client/src/geminiai-client.service.spec.ts`

```typescript
import { Test, TestingModule } from '@nestjs/testing'
import { HttpModule } from '@nestjs/axios'
import { ConfigModule } from '@nestjs/config'
import { GeminiAIClientService } from './geminiai-client.service'
import { GeminiAIClientModule } from './geminiai-client.module'

describe('GeminiAIClientService', () => {
  let service: GeminiAIClientService

  beforeEach(async () => {
    const module: TestingModule = await Test.createTestingModule({
      imports: [
        HttpModule,
        ConfigModule.forRoot({
          envFilePath: '.env.test',
        }),
        GeminiAIClientModule.forRoot({
          apiKey: process.env.GEMINI_API_KEY || 'test-key',
          baseUrl: 'https://generativelanguage.googleapis.com/v1beta',
        }),
      ],
    }).compile()

    service = module.get<GeminiAIClientService>(GeminiAIClientService)
  })

  it('should be defined', () => {
    expect(service).toBeDefined()
  })

  // Integration tests (require real API key)
  describe('Integration Tests', () => {
    it('should generate text content', async () => {
      if (!process.env.GEMINI_API_KEY) {
        console.log('Skipping integration test - no API key')
        return
      }

      const response = await service.generateText('Write a short poem about technology and innovation.')

      expect(response).toBeDefined()
      expect(response.candidates).toBeDefined()
      expect(response.candidates[0].content.parts[0].text).toBeDefined()
    })

    it('should list available models', async () => {
      if (!process.env.GEMINI_API_KEY) {
        console.log('Skipping integration test - no API key')
        return
      }

      const response = await service.listModels()
      expect(response).toBeDefined()
      expect(response.models).toBeDefined()
      expect(Array.isArray(response.models)).toBe(true)
    })

    it('should count tokens', async () => {
      if (!process.env.GEMINI_API_KEY) {
        console.log('Skipping integration test - no API key')
        return
      }

      const text = 'Hello, how are you today?'
      const response = await service.countTokens('gemini-2.5-flash', [{ parts: [{ text }] }])

      expect(response).toBeDefined()
      expect(response.totalTokens).toBeGreaterThan(0)
    })

    it('should generate embeddings', async () => {
      if (!process.env.GEMINI_API_KEY) {
        console.log('Skipping integration test - no API key')
        return
      }

      const response = await service.embedText(
        'This is a test sentence for embedding generation.',
        'text-embedding-004',
      )

      expect(response).toBeDefined()
      expect(response.embedding).toBeDefined()
      expect(response.embedding.values).toBeDefined()
      expect(Array.isArray(response.embedding.values)).toBe(true)
    })
  })
})
```

---

## üìù Step 14: Usage Examples

### Example 1: Simple Text Generation

```typescript
// In your service
const response = await this.aiService.generateText('Explain quantum computing in simple terms.')
console.log(response.text)
```

### Example 2: Image Analysis

```typescript
// Upload an image and analyze it
const analysisResult = await this.aiService.analyzeImage(
  imageBase64,
  'image/jpeg',
  'What objects can you identify in this image?',
)
console.log(analysisResult.analysis)
```

### Example 3: Structured Data Generation

```typescript
const schema = {
  type: 'object',
  properties: {
    summary: { type: 'string' },
    sentiment: { type: 'string', enum: ['positive', 'negative', 'neutral'] },
    keywords: { type: 'array', items: { type: 'string' } },
  },
}

const result = await this.aiService.generateStructuredData(
  'Analyze this product review: "Great product, fast delivery, highly recommended!"',
  schema,
)
console.log(result.data)
```

### Example 4: Function Calling

```typescript
const response = await this.aiService.callFunctions("What's the weather like in New York and what's 15 + 25?")
// AI will call the weather and calculator functions
```

---

## üîß Step 15: Final Commands

```bash
# 1. Generate the Gemini AI client
pnpm codegen

# 2. Install any missing dependencies
pnpm install @nestjs/axios multer

# 3. Build the project
pnpm build

# 4. Run tests
pnpm test libs/geminiai-client

# 5. Start the application
pnpm start:dev:bff
```

---

## ‚úÖ Final Checklist

- ‚úÖ Google AI Studio setup v√† API key configuration
- ‚úÖ OpenAPI specification v·ªõi t·∫•t c·∫£ Gemini API endpoints
- ‚úÖ NestJS dynamic module pattern implementation
- ‚úÖ Service wrapper v·ªõi comprehensive error handling
- ‚úÖ Type safety v·ªõi TypeScript v√† generated clients
- ‚úÖ Support cho text generation, multimodal, embeddings, function calling
- ‚úÖ Environment configuration v√† security best practices
- ‚úÖ Complete examples v√† integration guide
- ‚úÖ Test setup cho integration testing
- ‚úÖ Production-ready v·ªõi retry logic v√† monitoring

---

## üéØ Key Features Implemented

1. **Text Generation**: Simple v√† advanced prompts
2. **Multimodal AI**: Text + Image processing
3. **Function Calling**: AI c√≥ th·ªÉ g·ªçi external functions
4. **Embeddings**: Semantic search v√† similarity
5. **File Management**: Upload v√† process files
6. **Structured Output**: JSON schema-based responses
7. **Chat Conversations**: Multi-turn conversations
8. **Token Counting**: Cost optimization
9. **Model Management**: List v√† get model info
10. **Safety Settings**: Content safety controls

B√¢y gi·ªù b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng complete Gemini AI SDK trong NestJS project v·ªõi full type safety, error handling, v√† t·∫•t c·∫£ c√°c advanced features c·ªßa Google Gemini AI!
